{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcb2d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2382768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31acc2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('musical.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a70aae3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This the second set of strap locks that I've o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First of all I want to say I love a tube amp d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i only bought with the idea that a \"FULL\" vers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you're like me, you probably bought this to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Didn't know what to expect for under $10, but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>It really pains me to give anything but a 5-st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>It's a decent unit, but stopped working comple...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>I bought this cable in order to be able to run...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Well made. Works as it should. However, seem t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Like most products on the market, depending on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Score\n",
       "0    This the second set of strap locks that I've o...      1\n",
       "1    First of all I want to say I love a tube amp d...      1\n",
       "2    i only bought with the idea that a \"FULL\" vers...      0\n",
       "3    If you're like me, you probably bought this to...      1\n",
       "4    Didn't know what to expect for under $10, but ...      1\n",
       "..                                                 ...    ...\n",
       "995  It really pains me to give anything but a 5-st...      1\n",
       "996  It's a decent unit, but stopped working comple...      0\n",
       "997  I bought this cable in order to be able to run...      1\n",
       "998  Well made. Works as it should. However, seem t...      1\n",
       "999  Like most products on the market, depending on...      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48f19f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "# convert the text to lowercase\n",
    "df['Review'] = df['Review'].apply(lambda x: x.lower())\n",
    "\n",
    "# remove punctuation\n",
    "punct = string.punctuation\n",
    "df['Review'] = df['Review'].apply(lambda x: ''.join([char for char in x if char not in punct]))\n",
    "\n",
    "# remove numbers\n",
    "df['Review'] = df['Review'].apply(lambda x: ''.join([char for char in x if not char.isdigit()]))\n",
    "\n",
    "# remove stopwords\n",
    "stopwords = set(stopwords.words('english'))\n",
    "df['Review'] = df['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71bf7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the reviews\n",
    "df['tokens'] = df['Review'].apply(lambda x: word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3931038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stemming\n",
    "stemmer = PorterStemmer()\n",
    "df['stemmed_tokens'] = df['tokens'].apply(lambda x: [stemmer.stem(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762943b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second set strap locks ive owned little diffic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[second, set, strap, locks, ive, owned, little...</td>\n",
       "      <td>[second, set, strap, lock, ive, own, littl, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first want say love tube amp distortion overdr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, want, say, love, tube, amp, distortion...</td>\n",
       "      <td>[first, want, say, love, tube, amp, distort, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought idea full version behringers sequence p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, idea, full, version, behringers, sequ...</td>\n",
       "      <td>[bought, idea, full, version, behring, sequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre like probably bought hook xlr microphone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[youre, like, probably, bought, hook, xlr, mic...</td>\n",
       "      <td>[your, like, probabl, bought, hook, xlr, micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>didnt know expect proved worth gamblethis cabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[didnt, know, expect, proved, worth, gamblethi...</td>\n",
       "      <td>[didnt, know, expect, prove, worth, gamblethi,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>really pains give anything star review boss pr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[really, pains, give, anything, star, review, ...</td>\n",
       "      <td>[realli, pain, give, anyth, star, review, boss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>decent unit stopped working completely months ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[decent, unit, stopped, working, completely, m...</td>\n",
       "      <td>[decent, unit, stop, work, complet, month, tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>bought cable order able run longer cable runs ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[bought, cable, order, able, run, longer, cabl...</td>\n",
       "      <td>[bought, cabl, order, abl, run, longer, cabl, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>well made works however seem getting little bi...</td>\n",
       "      <td>1</td>\n",
       "      <td>[well, made, works, however, seem, getting, li...</td>\n",
       "      <td>[well, made, work, howev, seem, get, littl, bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>like products market depending item used exper...</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, products, market, depending, item, used...</td>\n",
       "      <td>[like, product, market, depend, item, use, exp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Score  \\\n",
       "0    second set strap locks ive owned little diffic...      1   \n",
       "1    first want say love tube amp distortion overdr...      1   \n",
       "2    bought idea full version behringers sequence p...      0   \n",
       "3    youre like probably bought hook xlr microphone...      1   \n",
       "4    didnt know expect proved worth gamblethis cabl...      1   \n",
       "..                                                 ...    ...   \n",
       "995  really pains give anything star review boss pr...      1   \n",
       "996  decent unit stopped working completely months ...      0   \n",
       "997  bought cable order able run longer cable runs ...      1   \n",
       "998  well made works however seem getting little bi...      1   \n",
       "999  like products market depending item used exper...      1   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [second, set, strap, locks, ive, owned, little...   \n",
       "1    [first, want, say, love, tube, amp, distortion...   \n",
       "2    [bought, idea, full, version, behringers, sequ...   \n",
       "3    [youre, like, probably, bought, hook, xlr, mic...   \n",
       "4    [didnt, know, expect, proved, worth, gamblethi...   \n",
       "..                                                 ...   \n",
       "995  [really, pains, give, anything, star, review, ...   \n",
       "996  [decent, unit, stopped, working, completely, m...   \n",
       "997  [bought, cable, order, able, run, longer, cabl...   \n",
       "998  [well, made, works, however, seem, getting, li...   \n",
       "999  [like, products, market, depending, item, used...   \n",
       "\n",
       "                                        stemmed_tokens  \n",
       "0    [second, set, strap, lock, ive, own, littl, di...  \n",
       "1    [first, want, say, love, tube, amp, distort, o...  \n",
       "2    [bought, idea, full, version, behring, sequenc...  \n",
       "3    [your, like, probabl, bought, hook, xlr, micro...  \n",
       "4    [didnt, know, expect, prove, worth, gamblethi,...  \n",
       "..                                                 ...  \n",
       "995  [realli, pain, give, anyth, star, review, boss...  \n",
       "996  [decent, unit, stop, work, complet, month, tri...  \n",
       "997  [bought, cabl, order, abl, run, longer, cabl, ...  \n",
       "998  [well, made, work, howev, seem, get, littl, bi...  \n",
       "999  [like, product, market, depend, item, use, exp...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe977fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_tokens'] = df['stemmed_tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5743f3f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second set strap locks ive owned little diffic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[second, set, strap, locks, ive, owned, little...</td>\n",
       "      <td>[second, set, strap, lock, ive, own, littl, di...</td>\n",
       "      <td>[second, set, strap, lock, ive, own, littl, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first want say love tube amp distortion overdr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, want, say, love, tube, amp, distortion...</td>\n",
       "      <td>[first, want, say, love, tube, amp, distort, o...</td>\n",
       "      <td>[first, want, say, love, tube, amp, distort, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought idea full version behringers sequence p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, idea, full, version, behringers, sequ...</td>\n",
       "      <td>[bought, idea, full, version, behring, sequenc...</td>\n",
       "      <td>[bought, idea, full, version, behring, sequenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre like probably bought hook xlr microphone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[youre, like, probably, bought, hook, xlr, mic...</td>\n",
       "      <td>[your, like, probabl, bought, hook, xlr, micro...</td>\n",
       "      <td>[your, like, probabl, bought, hook, xlr, micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>didnt know expect proved worth gamblethis cabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[didnt, know, expect, proved, worth, gamblethi...</td>\n",
       "      <td>[didnt, know, expect, prove, worth, gamblethi,...</td>\n",
       "      <td>[didnt, know, expect, prove, worth, gamblethi,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Score  \\\n",
       "0  second set strap locks ive owned little diffic...      1   \n",
       "1  first want say love tube amp distortion overdr...      1   \n",
       "2  bought idea full version behringers sequence p...      0   \n",
       "3  youre like probably bought hook xlr microphone...      1   \n",
       "4  didnt know expect proved worth gamblethis cabl...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [second, set, strap, locks, ive, owned, little...   \n",
       "1  [first, want, say, love, tube, amp, distortion...   \n",
       "2  [bought, idea, full, version, behringers, sequ...   \n",
       "3  [youre, like, probably, bought, hook, xlr, mic...   \n",
       "4  [didnt, know, expect, proved, worth, gamblethi...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [second, set, strap, lock, ive, own, littl, di...   \n",
       "1  [first, want, say, love, tube, amp, distort, o...   \n",
       "2  [bought, idea, full, version, behring, sequenc...   \n",
       "3  [your, like, probabl, bought, hook, xlr, micro...   \n",
       "4  [didnt, know, expect, prove, worth, gamblethi,...   \n",
       "\n",
       "                                   lemmatized_tokens  \n",
       "0  [second, set, strap, lock, ive, own, littl, di...  \n",
       "1  [first, want, say, love, tube, amp, distort, o...  \n",
       "2  [bought, idea, full, version, behring, sequenc...  \n",
       "3  [your, like, probabl, bought, hook, xlr, micro...  \n",
       "4  [didnt, know, expect, prove, worth, gamblethi,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d761e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the tokens to string format for model training\n",
    "df['lemmatized_tokens_str'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f2fdd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Score</th>\n",
       "      <th>tokens</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "      <th>lemmatized_tokens</th>\n",
       "      <th>lemmatized_tokens_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>second set strap locks ive owned little diffic...</td>\n",
       "      <td>1</td>\n",
       "      <td>[second, set, strap, locks, ive, owned, little...</td>\n",
       "      <td>[second, set, strap, lock, ive, own, littl, di...</td>\n",
       "      <td>[second, set, strap, lock, ive, own, littl, di...</td>\n",
       "      <td>second set strap lock ive own littl difficult ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>first want say love tube amp distortion overdr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[first, want, say, love, tube, amp, distortion...</td>\n",
       "      <td>[first, want, say, love, tube, amp, distort, o...</td>\n",
       "      <td>[first, want, say, love, tube, amp, distort, o...</td>\n",
       "      <td>first want say love tube amp distort overdrive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bought idea full version behringers sequence p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[bought, idea, full, version, behringers, sequ...</td>\n",
       "      <td>[bought, idea, full, version, behring, sequenc...</td>\n",
       "      <td>[bought, idea, full, version, behring, sequenc...</td>\n",
       "      <td>bought idea full version behring sequenc progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>youre like probably bought hook xlr microphone...</td>\n",
       "      <td>1</td>\n",
       "      <td>[youre, like, probably, bought, hook, xlr, mic...</td>\n",
       "      <td>[your, like, probabl, bought, hook, xlr, micro...</td>\n",
       "      <td>[your, like, probabl, bought, hook, xlr, micro...</td>\n",
       "      <td>your like probabl bought hook xlr microphon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>didnt know expect proved worth gamblethis cabl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[didnt, know, expect, proved, worth, gamblethi...</td>\n",
       "      <td>[didnt, know, expect, prove, worth, gamblethi,...</td>\n",
       "      <td>[didnt, know, expect, prove, worth, gamblethi,...</td>\n",
       "      <td>didnt know expect prove worth gamblethi cabl a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Score  \\\n",
       "0  second set strap locks ive owned little diffic...      1   \n",
       "1  first want say love tube amp distortion overdr...      1   \n",
       "2  bought idea full version behringers sequence p...      0   \n",
       "3  youre like probably bought hook xlr microphone...      1   \n",
       "4  didnt know expect proved worth gamblethis cabl...      1   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [second, set, strap, locks, ive, owned, little...   \n",
       "1  [first, want, say, love, tube, amp, distortion...   \n",
       "2  [bought, idea, full, version, behringers, sequ...   \n",
       "3  [youre, like, probably, bought, hook, xlr, mic...   \n",
       "4  [didnt, know, expect, proved, worth, gamblethi...   \n",
       "\n",
       "                                      stemmed_tokens  \\\n",
       "0  [second, set, strap, lock, ive, own, littl, di...   \n",
       "1  [first, want, say, love, tube, amp, distort, o...   \n",
       "2  [bought, idea, full, version, behring, sequenc...   \n",
       "3  [your, like, probabl, bought, hook, xlr, micro...   \n",
       "4  [didnt, know, expect, prove, worth, gamblethi,...   \n",
       "\n",
       "                                   lemmatized_tokens  \\\n",
       "0  [second, set, strap, lock, ive, own, littl, di...   \n",
       "1  [first, want, say, love, tube, amp, distort, o...   \n",
       "2  [bought, idea, full, version, behring, sequenc...   \n",
       "3  [your, like, probabl, bought, hook, xlr, micro...   \n",
       "4  [didnt, know, expect, prove, worth, gamblethi,...   \n",
       "\n",
       "                               lemmatized_tokens_str  \n",
       "0  second set strap lock ive own littl difficult ...  \n",
       "1  first want say love tube amp distort overdrive...  \n",
       "2  bought idea full version behring sequenc progr...  \n",
       "3  your like probabl bought hook xlr microphon di...  \n",
       "4  didnt know expect prove worth gamblethi cabl a...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "706edd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce528762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[57 29]\n",
      " [37 77]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63        86\n",
      "           1       0.73      0.68      0.70       114\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.67      0.67      0.67       200\n",
      "weighted avg       0.67      0.67      0.67       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# create the feature vector using CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "# convert the tokens to string format for model training\n",
    "df['lemmatized_tokens_str'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_tokens_str'], df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# create the feature vector using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# create the Decision Tree model\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# train the model\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# generate classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9af86dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[70 16]\n",
      " [23 91]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.81      0.78        86\n",
      "           1       0.85      0.80      0.82       114\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.80      0.81      0.80       200\n",
      "weighted avg       0.81      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# convert the tokens to string format for model training\n",
    "df['lemmatized_tokens_str'] = df['lemmatized_tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['lemmatized_tokens_str'], df['Score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# create the feature vector using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# create the Naive Bayes model\n",
    "nb = MultinomialNB()\n",
    "\n",
    "# train the model\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing set\n",
    "y_pred = nb.predict(X_test)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "# generate classification report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa90a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
