{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d22d2e5",
   "metadata": {},
   "source": [
    "Q3- Compare Neural Network and SVM in Classification of heart disease data set in R or Python\n",
    "language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef19747",
   "metadata": {},
   "source": [
    "To answer this question we have used Python language. First we compared different kernel for SVM and then we compared Stochastic Gradient Descent and Adamn for ANN. Finally compared ANN and SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a468b056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aa444e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv(\"heart.csv\")\n",
    "\n",
    "X = heart.drop(columns=[\"target\"])\n",
    "y = heart[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02eb198c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear kernel accuracy: 0.8048780487804879\n",
      "Confusion matrix\n",
      "[[72 30]\n",
      " [10 93]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.71      0.78       102\n",
      "           1       0.76      0.90      0.82       103\n",
      "\n",
      "    accuracy                           0.80       205\n",
      "   macro avg       0.82      0.80      0.80       205\n",
      "weighted avg       0.82      0.80      0.80       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Linear kernel\n",
    "svc_linear = svm.SVC(kernel=\"linear\")\n",
    "svc_linear.fit(X_train, y_train)\n",
    "y_pred=svc_linear.predict(X_test)\n",
    "linear_acc = svc_linear.score(X_test, y_test)\n",
    "print(\"Linear kernel accuracy:\", linear_acc)\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0441cf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian kernel accuracy: 0.6829268292682927\n",
      "Confusion matrix\n",
      "[[62 40]\n",
      " [25 78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.61      0.66       102\n",
      "           1       0.66      0.76      0.71       103\n",
      "\n",
      "    accuracy                           0.68       205\n",
      "   macro avg       0.69      0.68      0.68       205\n",
      "weighted avg       0.69      0.68      0.68       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Gaussian kernel\n",
    "rbf_svc = svm.SVC(kernel='rbf')\n",
    "rbf_svc.fit(X_train, y_train)\n",
    "y_pred=rbf_svc.predict(X_test)\n",
    "rbf_svc_acc = rbf_svc.score(X_test, y_test)\n",
    "print(f\"Gaussian kernel accuracy: {rbf_svc_acc}\")\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e95b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid kernel accuracy: 0.4926829268292683\n",
      "Confusion matrix\n",
      "[[47 55]\n",
      " [49 54]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.46      0.47       102\n",
      "           1       0.50      0.52      0.51       103\n",
      "\n",
      "    accuracy                           0.49       205\n",
      "   macro avg       0.49      0.49      0.49       205\n",
      "weighted avg       0.49      0.49      0.49       205\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sigmoid kernel\n",
    "sigmoid_svc = svm.SVC(kernel='sigmoid')\n",
    "sigmoid_svc.fit(X_train, y_train)\n",
    "y_pred=sigmoid_svc.predict(X_test)\n",
    "sigmoid_svc_acc = sigmoid_svc.score(X_test, y_test)\n",
    "print(f\"Sigmoid kernel accuracy: {sigmoid_svc_acc}\")\n",
    "print(\"Confusion matrix\")\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eea2dbec",
   "metadata": {},
   "source": [
    "In above codes we show the accuracy on the test set. As we can see, the linear  kernels perform similarly well, with an accuracy of 0.804. However, the Gaussian and sigmoid kernels perform significantly worse, with an accuracy of only 0.68 and 0.49 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0a833f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading tensorflow-2.11.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.11.0\n",
      "  Downloading tensorflow_intel-2.11.0-cp39-cp39-win_amd64.whl (266.3 MB)\n",
      "     -------------------------------------- 266.3/266.3 MB 9.3 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Using cached tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 18.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (21.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (4.3.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 21.5 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.21.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (63.4.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.3-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "     ---------------------------------------- 3.7/3.7 MB 17.0 MB/s eta 0:00:00\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     ------------------------------------- 895.9/895.9 kB 18.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (1.14.1)\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     -------------------------------------- 439.2/439.2 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.11.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.11.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ------------------------------------- 781.3/781.3 kB 16.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.3)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "     ------------------------------------- 177.2/177.2 kB 11.1 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.11.0->tensorflow) (3.0.9)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.2.8)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (1.26.11)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-intel==2.11.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Installing collected packages: tensorboard-plugin-wit, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 flatbuffers-23.3.3 gast-0.4.0 google-auth-2.16.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.3 keras-2.11.0 libclang-15.0.6.1 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.19.6 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-intel-2.11.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.2.0\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28f204db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "52/52 [==============================] - 1s 8ms/step - loss: 8.2016 - accuracy: 0.4927 - val_loss: 0.6936 - val_accuracy: 0.4976\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6931 - accuracy: 0.5146 - val_loss: 0.6856 - val_accuracy: 0.5024\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6919 - accuracy: 0.5159 - val_loss: 0.6862 - val_accuracy: 0.5024\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6907 - accuracy: 0.5159 - val_loss: 0.6823 - val_accuracy: 0.5024\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5159 - val_loss: 1.0016 - val_accuracy: 0.5024\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6739 - accuracy: 0.6183 - val_loss: 0.6824 - val_accuracy: 0.5415\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6755 - accuracy: 0.5817 - val_loss: 0.6769 - val_accuracy: 0.5512\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6648 - accuracy: 0.6268 - val_loss: 0.6765 - val_accuracy: 0.5512\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6628 - accuracy: 0.6256 - val_loss: 0.6857 - val_accuracy: 0.5610\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6580 - accuracy: 0.6317 - val_loss: 0.6703 - val_accuracy: 0.5902\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6585 - accuracy: 0.6537 - val_loss: 0.6851 - val_accuracy: 0.5756\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.6195 - val_loss: 0.7440 - val_accuracy: 0.6293\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6579 - accuracy: 0.6183 - val_loss: 0.6880 - val_accuracy: 0.5171\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.5890 - val_loss: 0.6833 - val_accuracy: 0.5317\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.6488 - val_loss: 0.6641 - val_accuracy: 0.6049\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.6451 - val_loss: 0.6758 - val_accuracy: 0.5561\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.6549 - val_loss: 0.7038 - val_accuracy: 0.5854\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6272 - accuracy: 0.6476 - val_loss: 0.6649 - val_accuracy: 0.5610\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6235 - accuracy: 0.6537 - val_loss: 0.9530 - val_accuracy: 0.6341\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6524 - val_loss: 0.6685 - val_accuracy: 0.6146\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6339 - accuracy: 0.6524 - val_loss: 0.6566 - val_accuracy: 0.6195\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6768 - val_loss: 0.6531 - val_accuracy: 0.6293\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.6695 - val_loss: 0.6553 - val_accuracy: 0.6098\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6176 - accuracy: 0.6707 - val_loss: 0.6575 - val_accuracy: 0.6000\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.6561 - val_loss: 0.6589 - val_accuracy: 0.6293\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6695 - val_loss: 0.6518 - val_accuracy: 0.6098\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.6646 - val_loss: 0.6643 - val_accuracy: 0.6195\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.6695 - val_loss: 0.6557 - val_accuracy: 0.6049\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.6793 - val_loss: 0.7310 - val_accuracy: 0.6293\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6132 - accuracy: 0.6695 - val_loss: 0.7674 - val_accuracy: 0.6341\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.6573 - val_loss: 0.9929 - val_accuracy: 0.6244\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.6817 - val_loss: 0.6663 - val_accuracy: 0.5756\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.6878 - val_loss: 0.6543 - val_accuracy: 0.6000\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6245 - accuracy: 0.6707 - val_loss: 0.8989 - val_accuracy: 0.6000\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6014 - accuracy: 0.7049 - val_loss: 0.6522 - val_accuracy: 0.6195\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6090 - accuracy: 0.6878 - val_loss: 0.6539 - val_accuracy: 0.6439\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6115 - accuracy: 0.6866 - val_loss: 0.6736 - val_accuracy: 0.5902\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6044 - accuracy: 0.6902 - val_loss: 0.6391 - val_accuracy: 0.6195\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6064 - accuracy: 0.6902 - val_loss: 0.6517 - val_accuracy: 0.6000\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6061 - accuracy: 0.6878 - val_loss: 0.6731 - val_accuracy: 0.5902\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5910 - accuracy: 0.7049 - val_loss: 0.7143 - val_accuracy: 0.5073\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.6683 - val_loss: 0.7628 - val_accuracy: 0.6585\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.6756 - val_loss: 0.6467 - val_accuracy: 0.6049\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6000 - accuracy: 0.6866 - val_loss: 0.6514 - val_accuracy: 0.6195\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.6817 - val_loss: 0.6519 - val_accuracy: 0.6634\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.6720 - val_loss: 0.6453 - val_accuracy: 0.6341\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6065 - accuracy: 0.6683 - val_loss: 0.7472 - val_accuracy: 0.6341\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.6878 - val_loss: 0.6557 - val_accuracy: 0.6439\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.6720 - val_loss: 0.6281 - val_accuracy: 0.6732\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6902 - val_loss: 0.7151 - val_accuracy: 0.6634\n",
      "Epoch 1/50\n",
      "52/52 [==============================] - 1s 8ms/step - loss: 3.1938 - accuracy: 0.5939 - val_loss: 0.6144 - val_accuracy: 0.6878\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.6064 - accuracy: 0.6963 - val_loss: 0.6297 - val_accuracy: 0.6195\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.5591 - accuracy: 0.7317 - val_loss: 0.5000 - val_accuracy: 0.7415\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4846 - accuracy: 0.7585 - val_loss: 0.5266 - val_accuracy: 0.7268\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7732 - val_loss: 0.4908 - val_accuracy: 0.7512\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.8110 - val_loss: 0.6518 - val_accuracy: 0.6439\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7878 - val_loss: 0.5053 - val_accuracy: 0.7707\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4199 - accuracy: 0.8146 - val_loss: 0.5462 - val_accuracy: 0.7366\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3814 - accuracy: 0.8329 - val_loss: 0.8367 - val_accuracy: 0.7073\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.4185 - accuracy: 0.8232 - val_loss: 0.4946 - val_accuracy: 0.7805\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.8073 - val_loss: 0.5097 - val_accuracy: 0.7220\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4041 - accuracy: 0.8268 - val_loss: 0.5079 - val_accuracy: 0.7366\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4003 - accuracy: 0.8280 - val_loss: 0.4971 - val_accuracy: 0.7512\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4160 - accuracy: 0.8268 - val_loss: 0.4430 - val_accuracy: 0.7902\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8378 - val_loss: 0.4517 - val_accuracy: 0.7707\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7988 - val_loss: 0.5840 - val_accuracy: 0.7317\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.8098 - val_loss: 0.4808 - val_accuracy: 0.7707\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3806 - accuracy: 0.8268 - val_loss: 0.5057 - val_accuracy: 0.7415\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.7866 - val_loss: 0.6842 - val_accuracy: 0.7366\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4028 - accuracy: 0.8268 - val_loss: 0.5965 - val_accuracy: 0.7512\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8268 - val_loss: 0.4363 - val_accuracy: 0.7756\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3781 - accuracy: 0.8390 - val_loss: 0.4441 - val_accuracy: 0.7561\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3745 - accuracy: 0.8451 - val_loss: 0.4589 - val_accuracy: 0.7854\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3732 - accuracy: 0.8512 - val_loss: 0.4579 - val_accuracy: 0.7805\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3854 - accuracy: 0.8378 - val_loss: 0.4557 - val_accuracy: 0.7902\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4043 - accuracy: 0.8207 - val_loss: 0.8104 - val_accuracy: 0.7415\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4133 - accuracy: 0.8134 - val_loss: 0.4589 - val_accuracy: 0.7902\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8232 - val_loss: 0.4519 - val_accuracy: 0.7512\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8207 - val_loss: 0.4421 - val_accuracy: 0.7707\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3627 - accuracy: 0.8512 - val_loss: 0.4476 - val_accuracy: 0.7463\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4139 - accuracy: 0.8098 - val_loss: 0.4999 - val_accuracy: 0.7561\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8488 - val_loss: 0.4335 - val_accuracy: 0.7805\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 0s 3ms/step - loss: 0.3817 - accuracy: 0.8305 - val_loss: 0.4432 - val_accuracy: 0.7854\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.8354 - val_loss: 0.4480 - val_accuracy: 0.7951\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3718 - accuracy: 0.8354 - val_loss: 0.4907 - val_accuracy: 0.7561\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3643 - accuracy: 0.8439 - val_loss: 0.4788 - val_accuracy: 0.7902\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3742 - accuracy: 0.8415 - val_loss: 0.6072 - val_accuracy: 0.7561\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3790 - accuracy: 0.8427 - val_loss: 0.4735 - val_accuracy: 0.7902\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3835 - accuracy: 0.8366 - val_loss: 0.4411 - val_accuracy: 0.7659\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3641 - accuracy: 0.8476 - val_loss: 0.4327 - val_accuracy: 0.8000\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3685 - accuracy: 0.8549 - val_loss: 0.4285 - val_accuracy: 0.8000\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.8329 - val_loss: 0.4275 - val_accuracy: 0.7951\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.3546 - accuracy: 0.8402 - val_loss: 0.4725 - val_accuracy: 0.7951\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.3477 - accuracy: 0.8573 - val_loss: 0.4450 - val_accuracy: 0.7951\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3973 - accuracy: 0.8268 - val_loss: 0.4570 - val_accuracy: 0.8049\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8561 - val_loss: 0.4913 - val_accuracy: 0.7756\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3457 - accuracy: 0.8549 - val_loss: 0.4705 - val_accuracy: 0.7951\n",
      "Epoch 48/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.8366 - val_loss: 0.4440 - val_accuracy: 0.7902\n",
      "Epoch 49/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8610 - val_loss: 0.4331 - val_accuracy: 0.7854\n",
      "Epoch 50/50\n",
      "52/52 [==============================] - 0s 4ms/step - loss: 0.4036 - accuracy: 0.8244 - val_loss: 0.4490 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebe4d736a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "\n",
    "# Define the neural network model using stochastic gradient descent\n",
    "model_sgd = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(13,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_sgd.compile(optimizer=SGD(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using stochastic gradient descent\n",
    "model_sgd.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Define the neural network model using Adam gradient descent\n",
    "model_adam = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(13,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_adam.compile(optimizer=Adam(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model using Adam gradient descent\n",
    "model_adam.fit(X_train, y_train, epochs=50, batch_size=16, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef4ac7fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.7151 - accuracy: 0.6634\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8000\n",
      "Stochastic Gradient Descent: [0.7151213884353638, 0.6634146571159363]\n",
      "Adam optimizer: [0.44895049929618835, 0.800000011920929]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the neural network models on the testing data\n",
    "score_sgd = model_sgd.evaluate(X_test, y_test)\n",
    "score_adam = model_adam.evaluate(X_test, y_test)\n",
    "\n",
    "print('Stochastic Gradient Descent:',score_sgd)\n",
    "print('Adam optimizer:',score_adam)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a627666c",
   "metadata": {},
   "source": [
    "On the heart disease dataset we have applied Stochastic Gradient Descent and Adam Gradient\n",
    "Descent to build the multi-layer Neural Network and note down the model accuracy for each.\n",
    "We can see from the above evaluation that the Adam model performs better than the SGD with an accuracy of 0.8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be4db08",
   "metadata": {},
   "source": [
    "As we can see, the SVM linear kernels perform similarly as ANN with adam optimizer, with an accuracy of 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54444ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
